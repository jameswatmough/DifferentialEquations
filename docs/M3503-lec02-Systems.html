<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="James Watmough">
<meta name="dcterms.date" content="2023-02-13">

<title>Math 3503: Differential Equations for Engineers - 3&nbsp; Systems of First order equations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./M3503-lec03-SecondOrderODE.html" rel="next">
<link href="./M3503-lec01-FirstOrderODE.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Systems of First order equations</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Math 3503: Differential Equations for Engineers</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">2023 Winter Test and Class Schedules</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M3503-lec01-ODEintro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M3503-lec01-FirstOrderODE.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">First order differential equations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M3503-lec02-Systems.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Systems of First order equations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M3503-lec03-SecondOrderODE.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Second order Linear Differential Equations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M3503-lec04-LaplaceTransforms.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Laplace Transforms</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M3503-lec05-FourierSeries.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Fourier Series</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-general-nonlinear-system-existence-and-uniqueness-of-solutions" id="toc-the-general-nonlinear-system-existence-and-uniqueness-of-solutions" class="nav-link active" data-scroll-target="#the-general-nonlinear-system-existence-and-uniqueness-of-solutions"><span class="toc-section-number">3.1</span>  The General Nonlinear System: Existence and Uniqueness of Solutions</a></li>
  <li><a href="#homogeneous-constant-coefficient-linear-systems" id="toc-homogeneous-constant-coefficient-linear-systems" class="nav-link" data-scroll-target="#homogeneous-constant-coefficient-linear-systems"><span class="toc-section-number">4</span>  Homogeneous Constant Coefficient Linear Systems</a>
  <ul class="collapse">
  <li><a href="#the-big-picture" id="toc-the-big-picture" class="nav-link" data-scroll-target="#the-big-picture"><span class="toc-section-number">4.1</span>  The big picture</a></li>
  <li><a href="#sec-diagon" id="toc-sec-diagon" class="nav-link" data-scroll-target="#sec-diagon"><span class="toc-section-number">4.2</span>  Real and Distinct Eigenvalues</a></li>
  <li><a href="#sec-complex" id="toc-sec-complex" class="nav-link" data-scroll-target="#sec-complex"><span class="toc-section-number">4.3</span>  Complex Eigenvalues</a></li>
  <li><a href="#sec-geneig" id="toc-sec-geneig" class="nav-link" data-scroll-target="#sec-geneig"><span class="toc-section-number">4.4</span>  Repeated Eigenvalues</a></li>
  <li><a href="#the-second-simplest-case" id="toc-the-second-simplest-case" class="nav-link" data-scroll-target="#the-second-simplest-case"><span class="toc-section-number">4.5</span>  The second simplest case</a></li>
  <li><a href="#generalized-eigenvectors" id="toc-generalized-eigenvectors" class="nav-link" data-scroll-target="#generalized-eigenvectors"><span class="toc-section-number">4.6</span>  Generalized Eigenvectors</a></li>
  <li><a href="#the-jordan-form" id="toc-the-jordan-form" class="nav-link" data-scroll-target="#the-jordan-form"><span class="toc-section-number">4.7</span>  The Jordan form</a></li>
  </ul></li>
  <li><a href="#the-nonhomogeneous-problem" id="toc-the-nonhomogeneous-problem" class="nav-link" data-scroll-target="#the-nonhomogeneous-problem"><span class="toc-section-number">5</span>  The nonhomogeneous problem</a>
  <ul class="collapse">
  <li><a href="#sec-varparm" id="toc-sec-varparm" class="nav-link" data-scroll-target="#sec-varparm"><span class="toc-section-number">5.1</span>  The method of variation of parameters</a></li>
  <li><a href="#the-solution-via-laplace-transforms" id="toc-the-solution-via-laplace-transforms" class="nav-link" data-scroll-target="#the-solution-via-laplace-transforms"><span class="toc-section-number">5.2</span>  The solution via Laplace Transforms</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-systems" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Systems of First order equations</span></span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>James Watmough </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 13, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="the-general-nonlinear-system-existence-and-uniqueness-of-solutions" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="the-general-nonlinear-system-existence-and-uniqueness-of-solutions"><span class="header-section-number">3.1</span> The General Nonlinear System: Existence and Uniqueness of Solutions</h2>
<p>Consider a system of differential equations of the form <span class="math inline">\(y'(t) = f(t,y(t))\)</span>, where <span class="math inline">\(f:{\mathbb R}\times{\mathbb R}^n\to{\mathbb R}^n\)</span> and we seek a solution <span class="math inline">\(y:{\mathbb R}\to {\mathbb R}^n\)</span>. That is, <span class="math inline">\(y\)</span> is a vector, or n-tuple of functions, and the function <span class="math inline">\(f\)</span> takes a vector and a real number as inputs and returns a vector as an output. The equations are often accompanied by initial conditions of the form <span class="math inline">\(y(t_0) = y_0\)</span>. The solution is a curve in <span class="math inline">\({\mathbb R}^n\)</span> parameterized by <span class="math inline">\(t\)</span> and passing through the point <span class="math inline">\(y_0\)</span>.</p>
<p>Sufficient conditions to guarantee the existence of a unique solution through any point are that <span class="math inline">\(f\)</span> be continuous in <span class="math inline">\(t\)</span> and differentiable in <span class="math inline">\(y\)</span>. However, a weaker condition than differentiability is also known to suffice.</p>
<div id="def-Lipschitz" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.1 (Lipschitz Continuity) </strong></span>A function <span class="math inline">\(f\)</span> is said to be Lipschitz continuous on some subset <span class="math inline">\(U\)</span> of its domain if there exists a constant <span class="math inline">\(M\)</span> for which <span class="math inline">\(\left\|f(x)-f(y)\right\| &lt; M\left\|x-y\right\|\)</span> whenever <span class="math inline">\(x,y\in U\)</span> with <span class="math inline">\(x\ne y\)</span>.</p>
</div>
<p>Equivalently, a function is Lipschitz continuous if the slopes of its secant lines are all bounded. For example, <span class="math inline">\(|x|\)</span> is Lipschitz continuous; <span class="math inline">\(x^{2/3}\)</span> is continuous but not Lipschitz since the secant lines tend towards vertical near the origin. Note, <span class="math inline">\(x^{2/3}\)</span> is (locally) Lipschitz so long as the set of interest is bounded away from the origin. In one dimension, <span class="math inline">\(\left\|x-y\right\|\)</span> can be assumed to be <span class="math inline">\(|x-y|\)</span>. In higher dimensions <span class="math inline">\(\left\|\cdot\right\|\)</span> is most often the standard Euclidian distance.</p>
<p>The classic result for the existence of solutions to our system of differential equations is as follows.</p>
<div id="thm-existence-uniqueness" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.1 </strong></span>If <span class="math inline">\(f(t,y)\)</span> is continuous in the independent variable, <span class="math inline">\(t\)</span>, and Lipschitz continuous in <span class="math inline">\(y\)</span>, then the initial value problem <span class="math inline">\(y' = f(t,y)\)</span>, <span class="math inline">\(y(t_0) = y_0\)</span> has a unique solution on some open interval <span class="math inline">\(a &lt; t_0 &lt; b\)</span>.</p>
</div>
<p>Various proofs of the above theorem can be found in most advanced books on differential equations.</p>
<div id="exm-intro-nonunique" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.1 </strong></span>An example for which solutions exist, but are not unique is the simple scalar initial value problem <span class="math inline">\(y' = y^{2/3}\)</span>, <span class="math inline">\(y(0) = 0\)</span>. The function <span class="math inline">\(y^{2/3}\)</span> is continuous for all <span class="math inline">\(y\)</span>, but has a cusp at the origin. It is not differentiable, nor is it Lipschitz continuous at the origin. Yet the differential equation is easily solved using the method of separation of variables, leading to the solutions <span class="math inline">\(y(t) = \frac{1}{3}(t+c)^3\)</span>. Taking <span class="math inline">\(c=0\)</span> gives a solution passing through the origin. A second obvious solution is <span class="math inline">\(y(t) = 0\)</span>. Moreover, we can splice these solutions together to get an infinite family of solutions to the initial value problem: <span class="math display">\[\begin{equation}
    y(t) = \begin{cases}
          \frac{1}{3}(t+c_1)^3 &amp; t &lt; -c_1  \\
          0 &amp; -c_1 \le t \le c_2 \\
          \frac{1}{3}(t-c_2)^3 &amp; t &gt; c_2  
           \end{cases}
   \end{equation}\]</span> with <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> arbitrary nonnegative constants.</p>
</div>
<p>Systems of higher order differential equations can be expressed as systems of linear equations by introducing the derivatives as new state variables.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.2 </strong></span>Express the second order equation <span class="math inline">\((t-3)y''(t) + t^2y'(t) + 7y(t) = f(t)\)</span> as a system of two first order equations.</p>
<p>Let <span class="math inline">\(z = y'\)</span>. Then the second order equation becomes <span class="math inline">\((t-3)z'(t) + t^2z(t) + 7y(t) = f(t)\)</span>. This together with the definition of <span class="math inline">\(z\)</span> gives a pair of first order equations. Dividing through by <span class="math inline">\((t-3)\)</span> puts the system in the basic form <span class="math display">\[\begin{align*}
    y'(t) &amp;= z(t) \\
    z'(t) &amp;=  -\frac{t^2}{t-3}z(t) - \frac{7}{t-3}y(t) + f(t)
  \end{align*}\]</span> The right hand side is linear, and hence differentiable, in <span class="math inline">\((y,z)\)</span> and continuous in <span class="math inline">\(t\)</span> on any interval bounded away from <span class="math inline">\(t=3\)</span>.</p>
</div>
</section>
<section id="homogeneous-constant-coefficient-linear-systems" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Homogeneous Constant Coefficient Linear Systems</h1>
<section id="the-big-picture" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="the-big-picture"><span class="header-section-number">4.1</span> The big picture</h2>
<p>Consider the linear system of ordinary differential equations <span class="math inline">\(x' = Ax\)</span> where <span class="math inline">\(x(t) = \left( x_1(t), x_2(t), \dots, x_n(t) \right)^T\)</span>and <span class="math inline">\(A\)</span> is an <span class="math inline">\(n\times n\)</span> matrix of real numbers (constants). The general theory for finding all solutions to the linear system is based on an eigenvalue decomposition of the matrix <span class="math inline">\(A\)</span>. Let <span class="math inline">\(r_1, r_2, \dots r_m\)</span> be the <span class="math inline">\(m\)</span> eigenvalues of <span class="math inline">\(A\)</span>. The theory of matrices and eigenvalues guarantees that <span class="math inline">\(A\)</span> has at least one eigenvalue, and no more than <span class="math inline">\(n\)</span> distinct eigenvalues, hence we can arrange things so that <span class="math inline">\(1 \le m \le n\)</span> and all the <span class="math inline">\(m\)</span> eigenvalues are distinct. That is, <span class="math inline">\(r_i=r_j \leftrightarrow i=j\)</span>. A handy theorem from linear algebra states that there is an invertible matrix <span class="math inline">\(S\)</span>, for which <span class="math inline">\(S^{-1}AS = \begin{pmatrix} J_1 &amp; &amp; 0 \\ &amp; \ddots &amp; \\ 0 &amp; &amp; J_m \end{pmatrix}\)</span>.</p>
<p>We know from linear algebra that each eigenvalue of <span class="math inline">\(A\)</span> has a multiplicity.</p>
</section>
<section id="sec-diagon" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-diagon"><span class="header-section-number">4.2</span> Real and Distinct Eigenvalues</h2>
<p>Consider the system <span class="math inline">\(y'=Ay\)</span> where <span class="math inline">\(A\)</span> is a real <span class="math inline">\(n\times n\)</span> matrix, and suppose that <span class="math inline">\(A\)</span> has a real eigenvalue <span class="math inline">\(r\)</span> with an associated eigenvector <span class="math inline">\(u\)</span>. Then <span class="math inline">\(y(t) = e^{rt}u\)</span> a solution. This is easy to verify by direct substitution.</p>
<p>Suppose <span class="math inline">\(u_1,\dots,u_m\)</span> are <span class="math inline">\(m\)</span> linearly independent eigenvectors of <span class="math inline">\(A\)</span> with associated eigenvalues <span class="math inline">\(r_1,\dots,r_m\)</span>. We look for a solution of the form <span class="math display">\[\begin{equation}y(t) = \sum_i^m x_i(t)u_i\end{equation}\]</span> Substituting this form into the differential equation leads to <span class="math display">\[\begin{equation} \sum_i^m x'_i(t)u_i = A\sum_i^m x_i(t)u_i = \sum_i^m r_ix_i(t)u_i \Rightarrow \sum_i^m \left(x'_i(t)-rx_i(t)\right)u_i = 0 \end{equation}\]</span> Since the vectors are linearly independent, it follows that <span class="math inline">\(x'_i(t)-rx_i(t) = 0\)</span>, <span class="math inline">\(i=1,\dots,m\)</span>, which has the solutions <span class="math inline">\(x_i(t) = c_ie^{r_it}\)</span>, <span class="math inline">\(i=1,\dots,m\)</span>, where each <span class="math inline">\(c_i\)</span> is an arbitrary constant. Thus, <span class="math display">\[\begin{equation}y(t) = \sum_i^m c_iu_ie^{r_it} \end{equation}\]</span> The effect of choosing the eigenvectors as a basis is to transform the system to a set of <span class="math inline">\(m\)</span> decoupled equations that have well-known solutions.</p>
</section>
<section id="sec-complex" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="sec-complex"><span class="header-section-number">4.3</span> Complex Eigenvalues</h2>
<p>Consider the system <span class="math inline">\(y'(t) = Ay(t)\)</span> where <span class="math inline">\(A\)</span> is a real <span class="math inline">\(n\times n\)</span> matrix, and suppose that <span class="math inline">\(A\)</span> has a complex eigenvalue <span class="math inline">\(r = a+bi\)</span> with an associated eigenvector <span class="math inline">\(u = v + iw\)</span>. It follows by direct substitution that <span class="math inline">\(v-iw\)</span> is also an eigenvector of <span class="math inline">\(A\)</span> associated with the eigenvalue <span class="math inline">\(a-ib\)</span>.</p>
<p>We seek a solution of the form <span class="math inline">\(y(t) = x_1(t) v + x_2(t) w\)</span> where <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are scalar functions of <span class="math inline">\(t\)</span>. Direct computation yields that <span class="math inline">\(A(x_1v + x_2w) = (ax_1 +bx_2)v + (-bx_1+ax_2)w\)</span>. Hence, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> must satisfy the pair of differential equations <span class="math display">\[\begin{align*}
    x_1'(t) &amp;= ax_1(t) +bx_2(t) \\
    x_2'(t) &amp;= -bx_1(t) +ax_2(t)
\end{align*}\]</span> Since <span class="math inline">\(e^{at}\)</span> is an integrating factor for both the above equations, <span class="math display">\[\begin{align}
  \frac{d}{dt} \left(x_1e^{-at}\right) &amp;= bx_2e^{-at}, \label{intfactx1}\\
\frac{d}{dt} \left(x_2e^{-at}\right) &amp;= -bx_1e^{-at}.\label{intfactx2}
\end{align}\]</span> Differentiating the first of these equations and eliminating <span class="math inline">\(x_2\)</span> using the second yields <span class="math display">\[\begin{equation}
\frac{d^2}{dt^2} \left(x_1e^{-at}\right) = b\frac{d}{dt}\left( x_2e^{-at}\right) = -b^2x_1e^{-at}.
\end{equation}\]</span> Hence, <span class="math inline">\(x_1e^{-at} = c_1\cos(bt) + c_2\sin(bt)\)</span>, which implies <span class="math inline">\(x_1(t)= e^{at}\left( c_1\cos(bt) + c_2\sin(bt)\right)\)</span>. To compute <span class="math inline">\(x_2\)</span> we use as follows: <span class="math display">\[\begin{align*}
bx_2e^{-at}
&amp;=  \frac{d}{dt} \left(x_1e^{-at}\right) \\
&amp;= \frac{d}{dt} \left( c_1\cos(bt) + c_2\sin(bt)\right) \\
&amp;= \left( -bc_1\sin(bt) + bc_2\cos(bt)\right) \\
x_2(t) &amp;= e^{at} \left( -c_1\sin(bt) + c_2\cos(bt)\right)
\end{align*}\]</span> A nice way to memorize these solutions is to write them in a matrix form. <span class="math display">\[\begin{equation}
  \begin{pmatrix} x_1(t) \\ x_2(t) \end{pmatrix} = e^{at}\begin{pmatrix} \cos(bt) &amp; \sin(bt) \\ -\sin(bt) &amp; \cos(bt) \end{pmatrix} \begin{pmatrix} c_1 \\ c_2 \end{pmatrix}
\end{equation}\]</span> The matrix on the right is the rotation matrix corresponding to counterclockwise rotation by the angle <span class="math inline">\(bt\)</span>. Hence, the solutions form a spiral in the <span class="math inline">\(u\)</span>-<span class="math inline">\(v\)</span> plane.</p>
<p>Returning to the original coordinates, <span class="math display">\[\begin{equation}
  y(t) = c_1e^{at}\left(v\cos(bt) - w\sin(bt)\right) + c_2e^{at}\left(v\sin(bt) + w\cos(bt)\right)  
\end{equation}\]</span> Note that up until now we have not specified the size of the original system. The solutions found above work regardless of the number of equations in the original system. If <span class="math inline">\(A\)</span> is a <span class="math inline">\(2\times2\)</span> matrix, then the solution can be expressed compactly by defining <span class="math inline">\(S\)</span> as the matrix whose columns are <span class="math inline">\(v\)</span> and <span class="math inline">\(w\)</span>. In this case <span class="math inline">\(y = Sx = e^{at}SR(bt)C\)</span> where <span class="math inline">\(R(\theta)\)</span> is the rotation matrix through angle <span class="math inline">\(\theta\)</span> and <span class="math inline">\(C\)</span> is the transpose of <span class="math inline">\(\begin{pmatrix} c_1 &amp; c_2\end{pmatrix}\)</span>. If we have initial conditions at <span class="math inline">\(t=0\)</span>, then <span class="math inline">\(y(0) = SC\)</span>, since <span class="math inline">\(R(0)\)</span> is the identity (rotation by zero). Thus, <span class="math inline">\(C= S^{-1}y(0)\)</span> and <span class="math display">\[\begin{equation}
  y(t) = e^{at}SR(bt)S^{-1}y(0).
\end{equation}\]</span></p>
</section>
<section id="sec-geneig" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="sec-geneig"><span class="header-section-number">4.4</span> Repeated Eigenvalues</h2>
<p>We have seen how to find solutions if we know a sufficient number of linearly independent eigenvectors. In this section we tackle the case where the geometric multiplicity of an eigenvalue (the dimension of the Eigenspace) is less than its algebraic multiplicity. We do this by first finding a general solution for a simple case and then derive a method to transform, through a change of basis, any other system to a similar simple system.</p>
</section>
<section id="the-second-simplest-case" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="the-second-simplest-case"><span class="header-section-number">4.5</span> The second simplest case</h2>
<p>Consider the system <span class="math display">\[\begin{align}
  \dot{x}_1(t) &amp;= rx_1(t) + x_2(t),  \label{simple1}\\
  \dot{x}_2(t) &amp;= rx_2(t), \label{simple2}
\end{align}\]</span> which when written in matrix form looks like <span class="math display">\[ \begin{pmatrix} \dot{x}_1 \\ \dot{x}_2 \end{pmatrix}  
  = \begin{pmatrix} r &amp; 1 \\ 0 &amp; r \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}  \]</span></p>
<p>The matrix <span class="math inline">\(J = \begin{pmatrix} r &amp; 1 \\ 0 &amp; r \end{pmatrix}\)</span> has a single eigenvalue <span class="math inline">\(r\)</span> with multiplicity 2. However, all eigenvectors of <span class="math inline">\(J\)</span> are multiples of <span class="math inline">\(\vec{u} = \begin{pmatrix}1 \\\ 0 \end{pmatrix}\)</span>. Hence, the eigenvalue <span class="math inline">\(r\)</span> has geometric multiplicity one.</p>
<p>To solve the system, first integrate to obtain <span class="math inline">\(x_2(t) = c_2e^{rt}\)</span>, then substitute this into and integrate a second time using the integrating factor <span class="math inline">\(e^{-rt}\)</span> to obtain <span class="math display">\[\begin{align*}
  \dot{x}_1(t) = rx_1(t) &amp;+ c_2e^{rt} \\
  \dot{x}_1(t) - rx_1(t) &amp;=  c_2e^{rt} \\
  \frac{d}{dt}\left({x}_1(t)e^{-rt}\right) &amp;=  c_2 \\
  {x}_1(t)e^{-rt} &amp;=  c_2t  + c_1\\
  {x}_1(t) &amp;=  c_2te^{rt}  + c_1e^{rt}
\end{align*}\]</span> This solution can be written in vector form as <span class="math display">\[\begin{equation}
  \begin{pmatrix} x_1(t) \\ x_2(t) \end{pmatrix}
    = c_1 e^{rt}\begin{pmatrix} 1 \\ 0 \end{pmatrix}
    + c_2 \left( te^{rt}\begin{pmatrix} 1 \\ 0 \end{pmatrix}  + e^{rt}\begin{pmatrix} 0 \\ 1 \end{pmatrix}\right)
\end{equation}\]</span> or in matrix form as <span class="math display">\[\begin{equation}
  \begin{pmatrix} x_1(t) \\ x_2(t) \end{pmatrix}
    = \begin{pmatrix} e^{rt}  &amp; te^{rt}\\ 0 &amp; e^{rt} \end{pmatrix}
      \begin{pmatrix} c_1 \\ c_2 \end{pmatrix}
\end{equation}\]</span> Both forms will be convenient at times.</p>
</section>
<section id="generalized-eigenvectors" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="generalized-eigenvectors"><span class="header-section-number">4.6</span> Generalized Eigenvectors</h2>
<div id="def-generalized-eigenvector" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.1 (Generalized eigenvector) </strong></span>A generalized eigenvector of <span class="math inline">\(A\)</span> is a vector <span class="math inline">\(v\)</span> for which <span class="math display">\[\left(A-rI\right)^m v = 0\]</span> for some positive integer <span class="math inline">\(m\)</span>.</p>
</div>
<p>Comments:</p>
<ul>
<li>Clearly, any eigenvector of <span class="math inline">\(A\)</span> is a generalized eigenvector (with <span class="math inline">\(m=1\)</span>).</li>
<li>If <span class="math inline">\(v\)</span> is a generalized eigenvector of <span class="math inline">\(A\)</span>, then the scalar <span class="math inline">\(\lambda\)</span> in the definition is an eigenvalue of <span class="math inline">\(A\)</span>. It also follows that <span class="math inline">\(u = \left(A-\lambda I\right)^{m-1}v\)</span> is an associated eigenvector.</li>
</ul>
<div id="thm-algebraic-multiplicity" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.1 </strong></span>If <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(A\)</span> with algebraic multiplicity <span class="math inline">\(k\)</span>, then the null space of <span class="math inline">\((A-\lambda I)^k\)</span> has dimension <span class="math inline">\(k\)</span>.</p>
</div>
<div id="thm-generalized-eigenvector-basis" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.2 </strong></span>Every matrix <span class="math inline">\(A\)</span> has a full set of generalized eigenvectors. That is, there is a (possibly complex) linearly independent set <span class="math inline">\(v_1,\dots,v_n\)</span> of generalized eigenvectors for every <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span>.</p>
</div>
<div id="exm-systems-1" class="theorem example">
<p><span class="theorem-title"><strong>Example 4.1 </strong></span>Consider the linear system <span class="math inline">\(\vec{y}' = A\vec{y}\)</span> with <span class="math inline">\(\vec{y}(0) = \vec{y}_0\)</span> and <span class="math display">\[\begin{equation} A = \begin{pmatrix} 4 &amp; -4 \\  1 &amp; 0 \end{pmatrix} \end{equation}\]</span> The characteristic polynomial for <span class="math inline">\(A\)</span> is <span class="math inline">\((4-r)(-r) -(-4)(1) = r^2 - 4r + 4 = (r-2)^2\)</span>. Hence, <span class="math inline">\(r_1 = 2\)</span> is an eigenvalue of <span class="math inline">\(A\)</span> with algebraic multiplicity 2. To find the eigenvectors of <span class="math inline">\(A\)</span> associated with <span class="math inline">\(r_1\)</span> we construct and simplify</p>
<p><span class="math display">\[(A -r_1I) = \begin{pmatrix} 4-2 &amp; -4 \\  1 &amp; 0-2 \end{pmatrix}  
               = \begin{pmatrix} 2 &amp; -4 \\  1 &amp; -2 \end{pmatrix}
               \sim \begin{pmatrix} 1 &amp; -2 \\  0 &amp; 0 \end{pmatrix}\]</span> Thus the solutions to <span class="math inline">\((A-2I)\vec{u} = 0\)</span> are all multiples of <span class="math inline">\(\vec{u} = \begin{pmatrix} 2 &amp; 1 \end{pmatrix}.\)</span> This is a one dimensional subspace. Hence <span class="math inline">\(r_1\)</span> has geometric multiplicity 1. As it turns out, the particular generalized eigenvector we want is a solution to <span class="math display">\[(A -r_1I)\vec{v}  = \vec{u}.\]</span> <span class="math inline">\(\vec{v}\)</span> will be a generalized eigenvector since <span class="math display">\[(A -r_1I)^2\vec{v}  = (A -r_1I)\vec{u} = 0.\]</span> To find <span class="math inline">\(\vec{v}\)</span>, we reduce the augmented matrix <span class="math display">\[\left(\begin{array}{cc|c} 2 &amp; -4 &amp; 2 \\ 1 &amp; -2 &amp; 1 \end{array} \right)
     \sim \left(\begin{array}{cc|c}  1 &amp; -2 &amp; 1\\ 0 &amp; 0 &amp; 0 \end{array} \right)\]</span> Thus, the entries of <span class="math inline">\(\vec{v}\)</span> satisfy <span class="math inline">\(v_1-2v_2 = 1\)</span>. Setting <span class="math inline">\(v_2 = a \in {\mathbb R}\)</span> give <span class="math inline">\(\vec{v} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} + \begin{pmatrix} 2 \\ 1 \end{pmatrix}a\)</span>. We will choose <span class="math inline">\(a=0\)</span> to give <span class="math inline">\(\vec{v} = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\)</span>. Note that <span class="math inline">\(\vec{u}\)</span> and <span class="math inline">\(\vec{v}\)</span> are linearly independent and hence form a basis for <span class="math inline">\({\mathbb R}^2\)</span>.</p>
<p>We look for solutions relative to this basis: <span class="math display">\[\vec{y}(t) = x_1(t)\vec{u} + x_2(t)\vec{v}\]</span> That is, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are the coordinates of our solution with respect to the basis <span class="math inline">\(\left\{ \vec{u},\vec{v}\right\}\)</span>. Substituting this form for <span class="math inline">\(\vec{y}\)</span> into the differential equation leads to <span class="math display">\[\begin{align*}
      x'_1(t)\vec{u} + x'_2(t)\vec{v} &amp;= x_1(t)A\vec{u} + x_2(t)A\vec{v}  \\
      &amp;= x_1(t)r_1\vec{u} + x_2(t)\left(r_1\vec{v} + \vec{u}\right)  \\
      &amp;= \left(r_1x_1(t) + x_2(t)\right)\vec{u} + r_1x_2(t)\vec{v}
   \end{align*}\]</span> Finally, equating the coefficients on both sides of the equation leads to the simpler system given by Equations (<span class="math inline">\(\ref{simple1}\)</span>) and (<span class="math inline">\(\ref{simple2}\)</span>) above, which have solutions <span class="math display">\[\begin{align*}
    x_1(t) &amp;=  c_2te^{r_1t}  + c_1e^{r_1t},\\  
    x_2(t) &amp;= c_2e^{r_1t}.
  \end{align*}\]</span> This leads to a solution for <span class="math inline">\(\vec{y}\)</span> of <span class="math display">\[\vec{y}(t) = \left(c_2te^{r_1t}  + c_1e^{r_1t}\right)\vec{u} + c_2e^{r_1t}\vec{v}
                = c_1e^{r_1t}\vec{u} + c_2\left(te^{r_1t}\vec{u} + e^{r_1t}\vec{v}\right)\]</span> For our example we have <span class="math inline">\(r_1 = 2\)</span>, <span class="math inline">\(\vec{u} = \begin{pmatrix} 2 \\ 1\end{pmatrix}\)</span> and <span class="math inline">\(\vec{v} = \begin{pmatrix} 1 \\ 0\end{pmatrix}\)</span>. Hence <span class="math display">\[\vec{y}(t) = c_1e^{r_1t}\begin{pmatrix} 2 \\ 1\end{pmatrix} + c_2\left(te^{r_1t}\begin{pmatrix} 2 \\ 1\end{pmatrix} + e^{r_1t}\begin{pmatrix} 1 \\ 0\end{pmatrix}\right)\]</span></p>
</div>
</section>
<section id="the-jordan-form" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="the-jordan-form"><span class="header-section-number">4.7</span> The Jordan form</h2>
<p>The question remains if we have found all the solutions. The answer to this lies in a theorem from linear algebra that states, roughly, that given any <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span>, there is a linearly independent set of generalized eigenvectors of <span class="math inline">\(A\)</span> that spans <span class="math inline">\({\mathbb R}^n\)</span>. Moreover, proceeding as we have above, we will find such a set. It can then be shown that the solutions we’ve found will be linearly independent and yield the complete general solution to <span class="math inline">\(y' = Ay\)</span>.</p>
</section>
</section>
<section id="the-nonhomogeneous-problem" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> The nonhomogeneous problem</h1>
<section id="sec-varparm" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-varparm"><span class="header-section-number">5.1</span> The method of variation of parameters</h2>
<p>Consider the system <span class="math display">\[\begin{equation}
  \frac{d}{dt}y(t) = Ay(t) + f(t), \qquad y(t_0) = y_0,  \label{nonhom}
\end{equation}\]</span> where <span class="math inline">\(A\)</span> is a given <span class="math inline">\(n\times n\)</span> matrix of real numbers and <span class="math inline">\(f\)</span> is a given vector-valued function from <span class="math inline">\({\mathbb R}\)</span> to <span class="math inline">\({\mathbb R}^n\)</span> Suppose we know <span class="math inline">\(n\)</span> linearly independent solutions to the homogeneous system <span class="math inline">\(y' = Ay\)</span>. Then the fundamental matrix, <span class="math inline">\(\Psi\)</span>, whose columns are these <span class="math inline">\(n\)</span> solutions satisfies <span class="math display">\[\begin{equation}
  \frac{d}{dt}\Psi(t) = A\Psi(t) + f(t).
\end{equation}\]</span> Applying the method of variation of parameters, we seek a solution to of the form <span class="math inline">\(y(t) = \Psi(t)u(t)\)</span>. Substituting this form into leads to <span class="math display">\[\Psi'u + \Psi u' = A\Psi u + f.\]</span> Since <span class="math inline">\(\Psi\)</span> is a solution to the homogeneous problem, the above equation reduces to <span class="math display">\[ \Psi u' =  f,\]</span> and hence, <span class="math display">\[\begin{equation}u(t) = \int \Psi^{-1}(t) f(t) \, dt.\end{equation}\]</span> To satisfy, the initial conditions, we choose the particular solution <span class="math inline">\(y_p = \Psi u\)</span> satisfying <span class="math inline">\(y_p(t_0) = y_0\)</span>. Then <span class="math display">\[\begin{equation}y(t) = \Psi(t)\Psi^{-1}(t_)y_0 + \Psi(t)\int_{t_0}^{t} \Psi^{-1}(\tau) f(\tau) \, d\tau.\end{equation}\]</span></p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.1 </strong></span>Consider the system <span class="math inline">\(y' = Ay + f\)</span> with <span class="math inline">\(A = \begin{pmatrix} 3 &amp; 3 \\ 1 &amp; 5 \end{pmatrix}\)</span> and <span class="math inline">\(f = \begin{pmatrix} t \\ e^{t} \end{pmatrix}.\)</span> The characteristic polynomial of <span class="math inline">\(A\)</span> is <span class="math inline">\((3-r)(5-r)-3 = (6-r)(6+r)\)</span>. The eigenvectors are <span class="math inline">\(r_1 = 6\)</span> and <span class="math inline">\(r_2 = 2\)</span> with associated eigenvectors <span class="math inline">\(u_1 = \begin{pmatrix} 1 \\ 1 \end{pmatrix}\)</span> and <span class="math inline">\(u_2 = \begin{pmatrix} 3 \\ -1 \end{pmatrix}\)</span>. Thus two linearly independent solutions to the homogeneous problem are <span class="math inline">\(y_1(t) = e^{6t}\begin{pmatrix} 1 \\ 1 \end{pmatrix}\)</span> and <span class="math inline">\(y_2(t) = e^{2t}\begin{pmatrix} 3 \\ -1 \end{pmatrix}\)</span>. One possible fundamental matrix is <span class="math display">\[\begin{equation}
    \Psi(t) = \begin{pmatrix} e^{6t} &amp; 3e^{2t} \\ e^{6t} &amp; -e^{2t} \end{pmatrix}
    = \begin{pmatrix} 1 &amp; 3 \\ 1 &amp; -1 \end{pmatrix}\begin{pmatrix} e^{6t} &amp; 0 \\ 0 &amp; e^{2t} \end{pmatrix}
  \end{equation}\]</span> Then <span class="math inline">\(\Psi^{-1}(t) = \frac{1}{4}\begin{pmatrix} e^{-6t} &amp; 3e^{-6t} \\ e^{-2t} &amp; -e^{-2t} \end{pmatrix}\)</span>, and<br>
<span class="math display">\[\begin{equation}
    \Psi(t)\Psi^{-1}(\tau) = \frac{1}{4}\begin{pmatrix} e^{6(t-\tau)}+3e^{2(t-\tau)} &amp; 3e^{6(t-\tau)}-3e^{2(t-\tau)} \\ e^{6(t-\tau)}-e^{2(t-\tau)} &amp; 3e^{6(t-\tau)}+e^{2(t-\tau)} \end{pmatrix}.
  \end{equation}\]</span> The complementary solution satisfying the initial conditions is <span class="math display">\[\begin{equation}
    y_c(t) = \Psi(t)\Psi^{-1}(0)y_0 = \frac{1}{4}\begin{pmatrix} e^{6t}+3e^{2t} &amp; 3e^{6t}-3e^{2t} \\ e^{6t}-e^{2t} &amp; 3e^{6t}+e^{2t} \end{pmatrix}y_0.
  \end{equation}\]</span> The particular solution satisfying <span class="math inline">\(y_p(0)=0\)</span> is <span class="math display">\[\begin{align*}
  y_p(t) &amp;= \int_0^t\Psi(t)\Psi^{-1}(\tau)f(\tau)\, d\tau  \\
  &amp;= \frac{1}{4}\int_0^t \strut \begin{pmatrix} \tau  e^{6(t-\tau)}+3\tau e^{2(t-\tau)} + 3e^{6t-5\tau}-3e^{2t-\tau} \\ \tau e^{6(t-\tau)}-\tau e^{2(t-\tau)} + 3e^{6t-5\tau}+e^{2t-\tau} \end{pmatrix}\begin{pmatrix} \tau \\ e^{\tau} \end{pmatrix} \, d\tau.\\
      &amp;=  {\small \begin{pmatrix}1\\1\end{pmatrix}}\int_0^t\tfrac{\tau}{4}  e^{6(t-\tau)} \,d\tau
        + {\small \begin{pmatrix}3\\-1\end{pmatrix}}\int_0^t \tfrac{\tau}{4} e^{2(t-\tau)} \,d\tau
        + {\small \begin{pmatrix}3\\3\end{pmatrix}}\int_0^t \tfrac{1}{4}e^{6t-5\tau} \,d\tau
        - {\small \begin{pmatrix}3\\-1\end{pmatrix}}\int_0^t \tfrac{1}{4}e^{2t-\tau} \,d\tau \\
      &amp;=  {\tiny \begin{pmatrix}1\\1\end{pmatrix}} \left( \tfrac{1}{144}-\tfrac{t}{24} -\tfrac{1}{144}e^{6t} \right)
      + {\tiny \begin{pmatrix}3\\-1\end{pmatrix}}  \left(\tfrac{1}{16} -\tfrac{t}{8} -\tfrac{1}{16}e^{2t} \right)
        + {\tiny \begin{pmatrix}3\\3\end{pmatrix}}  \left(\tfrac{1}{20}e^{6t} - \tfrac{1}{20}e^t \right)
    - {\tiny \begin{pmatrix}3\\-1\end{pmatrix}}  \left(\tfrac{1}{4}e^{2t} -\tfrac{1}{4}e^t  \right) \\
       &amp;=
          \tfrac{113}{720} e^{6t}{\small \begin{pmatrix} 1 \\ 1 \end{pmatrix}}
     -\tfrac{3}{16}e^{2t} {\small \begin{pmatrix} 3 \\ -1 \end{pmatrix}}
     -\tfrac{t}{12}{\small \begin{pmatrix} 5 \\ -1 \end{pmatrix}}
     -\tfrac{1}{36}{\small  \begin{pmatrix} 7 \\ 2 \end{pmatrix}}
     +\tfrac{1}{5}e^t {\small \begin{pmatrix} 3 \\ -2 \end{pmatrix}}
     \end{align*}\]</span></p>
<p>Note the first two terms are in fact homogeneous solutions that arise here to ensure the particular solution is zero when <span class="math inline">\(t=0\)</span>.<br>
The last three terms are of the form <span class="math inline">\(At + B + Ce^t\)</span> which we would expect from the method of undetermined coefficients, with the caveat that <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are vectors.</p>
<p>The general solution is simply <span class="math inline">\(y(t) = y_c(t) + y_p(t)\)</span> with the as-yet unspecified initial conditions taken as a pair of arbitrary constants.</p>
</div>
</section>
<section id="the-solution-via-laplace-transforms" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="the-solution-via-laplace-transforms"><span class="header-section-number">5.2</span> The solution via Laplace Transforms</h2>
<p>Applying the Laplace Transform to leads to <span class="math display">\[\begin{equation} sY(s) - y_0 = AY(s) + F(s).\end{equation}\]</span> Note that <span class="math inline">\(Y\)</span> is a vector whose entries are the transforms of the corresponding entry of <span class="math inline">\(y\)</span>. Since the transform is a linear operation (an integration), the matrix is essential pulled out of the integral. Solving for <span class="math inline">\(Y\)</span> we find <span class="math display">\[\begin{equation}Y(s) = (sI-A)^{-1}\left(y_0 + F\right).\end{equation}\]</span> Let <span class="math inline">\(G(s) = (sI-A)^{-1}\)</span> and <span class="math inline">\(g = {\mathcal L}^{-1}\left\{G\right\}\)</span>. Note that <span class="math inline">\(G\)</span> and <span class="math inline">\(g\)</span> are both <span class="math inline">\(n\times n\)</span> matrices. The solution to the differential equation can be represented as a convolution: <span class="math display">\[\begin{equation}y(t) = g(t)y_0 + \int_0^t g(t-\tau)f(\tau)\, d\tau.\end{equation}\]</span></p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.2 </strong></span>Consider the system <span class="math inline">\(y' = Ay + f\)</span> with <span class="math inline">\(A = \begin{pmatrix} 3 &amp; 3 \\ 1 &amp; 5 \end{pmatrix}\)</span> and <span class="math inline">\(f = \begin{pmatrix} t \\ e^{t} \end{pmatrix}.\)</span> <span class="math display">\[\begin{align*}  
    G(s) &amp;= (sI-A)^{-1} \\
         &amp;= \begin{pmatrix} s-3 &amp; -3 \\ -1 &amp; s-5 \end{pmatrix}\\
     &amp;= \begin{pmatrix} \frac{s-5}{(s-6)(s-2)} &amp;\ &amp; \frac{3}{(s-6)(s-2)} \\[6pt] \frac{1}{(s-6)(s-2)} &amp;\ &amp; \frac{s-3}{(s-6)(s-2)} \end{pmatrix} \\[12pt]
     &amp;= \frac{1}{4}\begin{pmatrix} \frac{1}{s-6} + \frac{3}{s-2} &amp;\ &amp; \frac{3}{s-6} - \frac{3}{s-2} \\[6pt] \frac{1}{s-6} - \frac{1}{s-2} &amp;\ &amp; \frac{3}{s-6} + \frac{1}{s-2} \end{pmatrix}\\[12pt]
    g(t) &amp;= \frac{1}{4}\begin{pmatrix} e^{6t} + 3e^{2t} &amp;\ &amp; 3e^{6t} - 3e^{2t} \\[6pt] e^{6t} - e^{2t} &amp;\ &amp; 3e^{6t} + e^{2t} \end{pmatrix}
  \end{align*}\]</span><br>
Note that the system for this example is the same as that of the previous example, and that <span class="math inline">\(g(t-\tau) = \Psi(t)\Psi^{-1}(\tau)\)</span> where <span class="math inline">\(\Psi\)</span> is the fundamental matrix from the previous example. Of course, <span class="math inline">\(g(t) = \Psi(t)\Psi^{-1}(0)\)</span>, which means the rest of the computations follow the previous example exactly. The two methods are identical!</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.3 </strong></span>&nbsp;</p>
Solve the system <span class="math inline">\(x' = Ax + g\)</span> where <span class="math inline">\(A = \begin{pmatrix} 4 &amp; 3 \\ -1 &amp; 0 \end{pmatrix}\)</span> and <span class="math inline">\(g = \begin{pmatrix} 0 \\ t \end{pmatrix}\)</span>.
<p>The matrix <span class="math inline">\(A\)</span> has two eigenvalues, <span class="math inline">\(r_1 = 1\)</span> and <span class="math inline">\(r_2=3\)</span>. Two associated eigenvectors are <span class="math inline">\(u_1 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}\)</span> and <span class="math inline">\(u_2 = \begin{pmatrix} 3 \\ -1 \end{pmatrix}\)</span>, respectively. Thus, a fundamental matrix for the system is <span class="math display">\[\Phi(t) = \begin{pmatrix} e^t &amp; 3e^{3t} \\ -e^t &amp; -e^{3t} \end{pmatrix}.\]</span> The method of variation of parameters gives the general solution in the form <span class="math display">\[x(t) = \Phi(t)\int \Phi^{-1}(t) g(t) \, dt.\]</span> Direct computations lead to <span class="math display">\[\begin{align*}
  \Phi^{-1}(t) &amp;= \frac{1}{2e^{4t}} \begin{pmatrix} -e^{3t} &amp; -3e^{3t} \\ e^t &amp; e^t \end{pmatrix} = \frac{1}{2}\begin{pmatrix} -e^{-t} &amp; -3e^{-t} \\ e^{-3t} &amp; e^{-3t} \end{pmatrix}. \\
  \Phi^{-1}(t)g(t) &amp;= \frac{1}{2}\begin{pmatrix} -e^{-t} &amp; -3e^{-t} \\ e^{-3t} &amp; e^{-3t} \end{pmatrix} \begin{pmatrix}0 \\ t \end{pmatrix}
                    =  \begin{pmatrix}  -\frac{3}{2}te^{-t} \\  \frac{1}{2}te^{-3t} \end{pmatrix}. \\
  \int\Phi^{-1}(t)g(t)\,dt &amp;=  \begin{pmatrix}  -\frac{3}{2}\int te^{-t} \,dt \\  \frac{1}{2} \int te^{-3t}\, dt \end{pmatrix}
                             =  \begin{pmatrix}  \frac{3}{2} e^{-t}(t+1) + c_1\\  \frac{1}{18} e^{-3t}(3t+1) + c_2 \end{pmatrix}. \\
    \Phi(t)\int\Phi^{-1}(t)g(t)\,dt
        &amp; =  \begin{pmatrix} e^t &amp; 3e^{3t} \\ -e^t &amp; -e^{3t} \end{pmatrix} \begin{pmatrix}  \frac{3}{2} e^{-t}(t+1) + c_1\\  \frac{1}{18} e^{-3t}(3t+1) + c_2 \end{pmatrix}. \\
    &amp;=  \begin{pmatrix} t +  \frac{4}{3} \\ -t - \frac{13}{9}\end{pmatrix} + c_1  e^t \begin{pmatrix} 1 \\ -1 \end{pmatrix}
    + c_2  e^{-3t} \begin{pmatrix} 3 \\ -1 \end{pmatrix}
  \end{align*}\]</span></p>
<p>Note the last two terms are the complementary solution. We could have ignored the constants of integration and simply added these on afterwards.</p>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./M3503-lec01-FirstOrderODE.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">First order differential equations</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./M3503-lec03-SecondOrderODE.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Second order Linear Differential Equations</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>